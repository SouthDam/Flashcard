{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ ME \n",
    "\n",
    "If a data set comes with separate .txt files,\n",
    "this file can convert them into one or several .csv files to benefit later operation\n",
    "\n",
    "Now the file is exclusively used for BBC News dataset.\n",
    "\n",
    "work flow:\n",
    "- create dataframe (id, original, summary)\n",
    "- read txt files\n",
    "- write file content into dataframe\n",
    "- save dataframe as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      original  summary\n",
      "0          NaN      NaN\n",
      "1          NaN      NaN\n",
      "2          NaN      NaN\n",
      "3          NaN      NaN\n",
      "4          NaN      NaN\n",
      "...        ...      ...\n",
      "2220       NaN      NaN\n",
      "2221       NaN      NaN\n",
      "2222       NaN      NaN\n",
      "2223       NaN      NaN\n",
      "2224       NaN      NaN\n",
      "\n",
      "[2225 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "ids = np.arange(1,2226,1).tolist()\n",
    "raw_data = {\n",
    "    \"original\":[np.NaN]*2225,\n",
    "    \"summary\":[np.NaN]*2225\n",
    "}\n",
    "df=pd.DataFrame(raw_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "all_path = r\"/Users/southdam/Desktop/Master-Project-Flashcard/BBC-News-Extractive/\"\n",
    "ori_path = all_path + r\"News Articles/business\"\n",
    "sum_path = all_path + r\"Summaries/business\"\n",
    "ori_walk = os.walk(ori_path)\n",
    "sum_walk = os.walk(sum_path)\n",
    "\n",
    "# Add original text into dataframe\n",
    "for path, __, file_list in ori_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"original\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "\n",
    "# Add summary into dataframe\n",
    "for path, __, file_list in sum_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"summary\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "print(\"business\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entertainment\n"
     ]
    }
   ],
   "source": [
    "all_path = r\"/Users/southdam/Desktop/Master-Project-Flashcard/BBC-News-Extractive/\"\n",
    "ori_path = all_path + r\"News Articles/entertainment\"\n",
    "sum_path = all_path + r\"Summaries/entertainment\"\n",
    "ori_walk = os.walk(ori_path)\n",
    "sum_walk = os.walk(sum_path)\n",
    "\n",
    "# Add original text into dataframe\n",
    "for path, __, file_list in ori_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1+510\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"original\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "\n",
    "# Add summary into dataframe\n",
    "for path, __, file_list in sum_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1+510\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"summary\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "print('entertainment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "politics\n"
     ]
    }
   ],
   "source": [
    "all_path = r\"/Users/southdam/Desktop/Master-Project-Flashcard/BBC-News-Extractive/\"\n",
    "ori_path = all_path + r\"News Articles/politics\"\n",
    "sum_path = all_path + r\"Summaries/politics\"\n",
    "ori_walk = os.walk(ori_path)\n",
    "sum_walk = os.walk(sum_path)\n",
    "\n",
    "# Add original text into dataframe\n",
    "for path, __, file_list in ori_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1+510+386\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"original\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "\n",
    "# Add summary into dataframe\n",
    "for path, __, file_list in sum_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1+510+386\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"summary\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "print('politics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sport\n"
     ]
    }
   ],
   "source": [
    "all_path = r\"/Users/southdam/Desktop/Master-Project-Flashcard/BBC-News-Extractive/\"\n",
    "ori_path = all_path + r\"News Articles/sport\"\n",
    "sum_path = all_path + r\"Summaries/sport\"\n",
    "ori_walk = os.walk(ori_path)\n",
    "sum_walk = os.walk(sum_path)\n",
    "\n",
    "# Add original text into dataframe\n",
    "for path, __, file_list in ori_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1+510+386+417\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"original\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "\n",
    "# Add summary into dataframe\n",
    "for path, __, file_list in sum_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1+510+386+417\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"summary\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "print('sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech\n"
     ]
    }
   ],
   "source": [
    "all_path = r\"/Users/southdam/Desktop/Master-Project-Flashcard/BBC-News-Extractive/\"\n",
    "ori_path = all_path + r\"News Articles/tech\"\n",
    "sum_path = all_path + r\"Summaries/tech\"\n",
    "ori_walk = os.walk(ori_path)\n",
    "sum_walk = os.walk(sum_path)\n",
    "\n",
    "# Add original text into dataframe\n",
    "for path, __, file_list in ori_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1+510+386+417+511\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"original\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "\n",
    "# Add summary into dataframe\n",
    "for path, __, file_list in sum_walk:  \n",
    "    for file_name in file_list: \n",
    "        if file_name==\".DS_Store\":\n",
    "            continue\n",
    "        this_path = os.path.join(path, file_name)\n",
    "        id_index = int(file_name.replace(\".txt\",\"\"))-1+510+386+417+511\n",
    "        with open(this_path, 'r') as f:\n",
    "            try:\n",
    "                text = f.read()\n",
    "                df.loc[id_index,\"summary\"]=text\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "print('tech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               original  \\\n",
      "0     Ad sales boost Time Warner profit\\n\\nQuarterly...   \n",
      "1     Dollar gains on Greenspan speech\\n\\nThe dollar...   \n",
      "2     Yukos unit buyer faces loan claim\\n\\nThe owner...   \n",
      "3     High fuel prices hit BA's profits\\n\\nBritish A...   \n",
      "4     Pernod takeover talk lifts Domecq\\n\\nShares in...   \n",
      "...                                                 ...   \n",
      "2220  BT program to beat dialler scams\\n\\nBT is intr...   \n",
      "2221  Spam e-mails tempt net shoppers\\n\\nComputer us...   \n",
      "2222  Be careful how you code\\n\\nA new European dire...   \n",
      "2223  US cyber security chief resigns\\n\\nThe man mak...   \n",
      "2224  Losing yourself in online gaming\\n\\nOnline rol...   \n",
      "\n",
      "                                                summary  \n",
      "0     TimeWarner said fourth quarter sales rose 2% t...  \n",
      "1     The dollar has hit its highest level against t...  \n",
      "2     Yukos' owner Menatep Group says it will ask Ro...  \n",
      "3     Rod Eddington, BA's chief executive, said the ...  \n",
      "4     Pernod has reduced the debt it took on to fund...  \n",
      "...                                                 ...  \n",
      "2220  BT is introducing two initiatives to help beat...  \n",
      "2221  A third of them read unsolicited junk e-mail a...  \n",
      "2222  This goes to the heart of the European project...  \n",
      "2223  Amit Yoran was director of the National Cyber ...  \n",
      "2224  He says that in the world of online gaming suc...  \n",
      "\n",
      "[2224 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df=df.dropna()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(r'/Users/southdam/Desktop/Master-Project-Flashcard/Real-Code/BBC-News.csv', \n",
    "          index = False)\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Code",
   "language": "python",
   "name": "code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
